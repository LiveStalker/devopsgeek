---
title: Машинное обучение, конспект, неделя 1
tags: machine-learning
---
Машинное обучение можно разделить на два больших класса:
* Обучение с учителем (Supervised Learning) --- мы даем алгоритму набор данных, которые содержат правильные ответы на
  поставленные вопросы их хотим, чтобы алгоритм выдавал проноз на будущих данных. Подобные задачи также называются задачами 
  регрессии (пример: определить стоимость дома, в зависимости от его площади) --- алогоритм должен предсказать значение 
  непрерывной велечины в будущем. Сюда же можно отнести задачи классификации
  (пример: определение типа опухоли по её размеру).
* Обучение без учителя (Unsupervised Learning) --- "Вот набор данных, есть ли в нём какая-либо структура". Алогоритмы
  кластеризации (например: google news), задачи обобщения, задачи поиска правил ассоциации, задачи сокращения
  размерности, задачи визуализации данных.

Для работы будем использовать Octave.

## Линейная регрессия

Введем следующие обозначения:

* m --- размерность обучающей выборки
* x`s --- входные переменные (признаки)
* y`s --- выходные переменные (целевые переменные)
* (x, y) --- одна строка выборки
* (x<sup>i</sup>, y<sup>i</sup>) --- кокретная строка

```
   Training Set
       \/
Learning Algorithm
       \/
Input > h > Estimated value

h --- hypothesis function (maps from x`s to y`s)
```

Вопрос: какого вида должна быть функция *h*.

Самый простой вариант:
$$h_{\theta} = \theta_{0} + \theta_{1}x$$

Параметры модели:

* \\(\theta_{0}\\)
* \\(\theta_{1}\\)


Мы можем начать с простой линейной функции, а уже потом перейти к более сложной. Модель в основе, которой лежит ЛФ
называется линейной регрессией.

## Cost function (функция затрат)

Каким образом нам подобрать параметры модели, чтобы добиться наилучших результатов?

Нужно минимизировать функцию:

$$J(\theta_0, \theta_1) = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left ( \hat{y}_{i}- y_{i} \right)^2 = \dfrac {1}{2m} \displaystyle \sum _{i=1}^m \left (h_\theta (x_{i}) - y_{i} \right)^2$$

### Дополнительные ресурсы

* [MSE](https://en.wikipedia.org/wiki/Mean_squared_error)

## Gradient descent (градиентный спуск)

$$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)$$

* \\(\alpha\\) - шаг (learning rate)
